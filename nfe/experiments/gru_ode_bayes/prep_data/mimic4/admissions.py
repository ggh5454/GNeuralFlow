# -*- coding: utf-8 -*-
"""admissions.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/127oHZQ8pYZa-dovtPqOHqjFIv0uCI8yA

# MIMIC 4 data - dataset construction admissions

Code taken from GRU-ODE-Bayes preprocessing; simplified and adapted for MIMIC 4 1.0
"""

import os
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime
from datetime import timedelta
import numpy as np
import torch.cuda

data_path = 'nfe/experiments/data/physionet.org/files/mimiciv/2.2'

hos = f'{data_path}/hosp'
icu_path = f'{data_path}/icu'
out_path = 'nfe/experiments/data'
proc_path = f'{out_path}/mimic4_processed'
os.makedirs(proc_path, exist_ok=True)

comp = 'gzip'

adm = pd.read_csv(f'{hos}/admissions.csv.gz', compression=comp)
# adm = pd.read_csv(f'{demo}/admissions.csv', compression=comp)
adm.head()

# keep only patients present in patients data
patients_df = pd.read_csv(f'{hos}/patients.csv.gz', compression=comp)
# patients_df = pd.read_csv(f'{demo}/patients.csv', compression=comp)

patients_df[["subject_id", "anchor_age"]].head()
adm_dob = pd.merge(patients_df[["subject_id", "anchor_age"]], adm, on="subject_id")

df = adm.groupby("subject_id")["hadm_id"].nunique()
subj_ids = list(df[df == 1].index)
adm_1 = adm_dob.loc[adm_dob["subject_id"].isin(subj_ids)]
print("Number of patients remaining in the dataframe: ")
print(len(adm_1.index))

# time of stay in ICU
adm_1 = adm_1.copy()
adm_1['admittime'] = pd.to_datetime(adm_1["admittime"], format='%Y-%m-%d %H:%M:%S')
adm_1['dischtime'] = pd.to_datetime(adm_1["dischtime"], format='%Y-%m-%d %H:%M:%S')

adm_1["elapsed_time"] = adm_1["dischtime"] - adm_1["admittime"]
adm_1.head()
adm_1["elapsed_days"] = adm_1["elapsed_time"].dt.days

adm_2 = adm_1.loc[(adm_1["elapsed_days"] < 30) & (adm_1["elapsed_days"] > 2)]
print("Number of patients remaining in the dataframe: ")
print(len(adm_2.index))

# only patients older than 15
adm_2_15 = adm_2.loc[adm_2["anchor_age"] > 15].copy()
print("Number of patients remaining in the dataframe: ")
print(len(adm_2_15.index))

fn = f'{icu_path}/chartevents.csv.gz'
# fn = f'{demo}/chartevents.csv'
# this file is huge, we need to read in the data in chunks
# chartevents = pd.read_csv(fn, compression='gzip')

# workaround:
ids = np.array([])
for chunk in pd.read_csv(fn, chunksize=1000000):
    ids = np.append(ids, chunk['hadm_id'].unique())
    ids = np.unique(ids)

adm_2_15_chart = adm_2_15.loc[adm_2_15["hadm_id"].isin(ids)].copy()
print("Number of patients remaining in the dataframe: ")
print(len(adm_2_15_chart.index))


adm_2_15_chart.to_csv(f"{proc_path}/admissions_processed.csv")
