# -*- coding: utf-8 -*-
"""labevents.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17E6HAU1BfBBh6Oz1jZcZ3s_1lizsBDcq

# MIMIC 4 data - dataset construction labevents

Code taken from GRU-ODE-Bayes preprocessing; simplified and adapted for MIMIC 4 1.0
"""

import os
import pandas as pd
# import matplotlib.pyplot as plt
# from datetime import datetime
# from datetime import timedelta
# import numpy as np
# from sklearn.model_selection import train_test_split

import torch
import os

pd.set_option('display.max_rows', 50)
pd.set_option('display.max_columns', 300)

data_path = 'nfe/experiments/data/physionet.org/files/mimiciv/2.2'

hos_path = f'{data_path}/hosp'
icu_path = f'{data_path}/icu'
out_path = 'nfe/experiments/data'
proc_path = f'{out_path}/mimic4_processed'
os.makedirs(proc_path, exist_ok=True)

adm = pd.read_csv(f"{proc_path}/admissions_processed.csv")
adm.head()

df = pd.DataFrame()
for chunk in pd.read_csv(f"{hos_path}/labevents.csv.gz", chunksize=500000):
    adm_ids = list(adm["hadm_id"])
    chunk = chunk.loc[chunk["hadm_id"].isin(adm_ids)]
    df = df.append(chunk[["subject_id", "hadm_id", "charttime", "valuenum", "itemid"]])

# only choose previously selected admission ids.
print("Number of patients remaining in the database: ")
print(df["subject_id"].nunique())

# get item ids
item_id = pd.read_csv(f"{hos_path}/d_labitems.csv.gz")
item_id_1 = item_id[["itemid", "label"]]
item_id_1.head()

# get names of administered items
lab2 = pd.merge(df, item_id_1, on="itemid")
lab2.head()
print("Number of patients remaining in the database: ")
print(lab2["subject_id"].nunique())

# get only top 150 most used tests
n_best = 150
pat_for_item = lab2.groupby("label")["subject_id"].nunique()
frequent_labels = pat_for_item.sort_values(ascending=False)[:n_best]
lab3 = lab2.loc[lab2["label"].isin(list(frequent_labels.index))].copy()

print("Number of patients remaining in the database: ")
print(lab3["subject_id"].nunique())

# only select the subset that was used in the paper (only missing is INR(PT))
subset = ["Albumin", "Alanine Aminotransferase (ALT)", "Alkaline Phosphatase", "Anion Gap",
          "Asparate Aminotransferase (AST)", "Base Excess", "Basophils", "Bicarbonate", "Bilirubin, Total",
          "Calcium, Total", "Calculated Total CO2", "Chloride", "Creatinine", "Eosinophils", "Glucose", "Hematocrit",
          "Hemoglobin", "Lactate", "Lymphocytes", "MCH", "MCV", "Magnesium", "Monocytes", "Neutrophils", "PT", "PTT",
          "Phosphate", "Platelet Count", "Potassium", "RDW", "Red Blood Cells", "Sodium", "Specific Gravity",
          "Urea Nitrogen", "White Blood Cells", "pCO2", "pH", "pO2"]

lab3 = lab3.loc[lab3["label"].isin(subset)].copy()

lab3.to_csv(f"{proc_path}/lab_processed.csv")
print('done')

